{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccf140c-cd62-4456-bf42-4a87039430e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9818a16a-431b-4e2b-815d-379f2eb8bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.25.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/294.9 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 235.5/294.9 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.9/294.9 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e018c4-7737-44c5-aa08-070d20aa145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 1/86\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48:02\u001b[0m 119s/step - accuracy: 0.0625 - loss: 3.5200"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Concatenate, ZeroPadding2D, LSTM\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "# Densenet201 Model Definition\n",
    "def densenet201_model(img_rows, img_cols, color_type=1, nb_dense_block=4, growth_rate=32, nb_filter=64, \n",
    "                      reduction=0.5, dropout_rate=0.0, weight_decay=1e-4, num_classes=None):\n",
    "    '''\n",
    "    DenseNet 201 Model for Keras\n",
    "    '''\n",
    "    global concat_axis\n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type), name='data')\n",
    "    concat_axis = 3\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 64\n",
    "    nb_layers = [6, 12, 48, 32]  # For DenseNet-201\n",
    "\n",
    "    # Initial convolution\n",
    "    x = Conv2D(nb_filter, (7, 7), strides=(2, 2), padding='same', name='conv1', use_bias=False)(img_input)\n",
    "    x = BatchNormalization(axis=concat_axis)(x)\n",
    "    # Commenting Scale, ensure custom scale layer is available\n",
    "    # x = Scale(axis=concat_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx + 2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate)\n",
    "        x = transition_block(x, stage, nb_filter, dropout_rate=dropout_rate)\n",
    "        nb_filter = int(nb_filter)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate)\n",
    "    x = BatchNormalization(axis=concat_axis)(x)\n",
    "    # x = Scale(axis=concat_axis)(x) # Optional: Use if Scale layer is defined\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x_fc = GlobalAveragePooling2D()(x)\n",
    "    x_fc = Dense(num_classes)(x_fc)\n",
    "    x_fc = Activation('softmax')(x_fc)\n",
    "\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    sgd = SGD(learning_rate=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Helper functions for Dense Blocks, Transition Blocks, etc.\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None):\n",
    "    inter_channel = nb_filter * 4  \n",
    "    x = BatchNormalization(axis=concat_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(inter_channel, (1, 1), use_bias=False)(x)  # Updated here\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D((1, 1))(x)\n",
    "    x = Conv2D(nb_filter, (3, 3), use_bias=False)(x)  # Updated here\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def transition_block(x, stage, nb_filter, dropout_rate=None):\n",
    "    x = BatchNormalization(axis=concat_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nb_filter), (1, 1), use_bias=False)(x)  # Updated here\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, grow_nb_filters=True):\n",
    "    '''Build a dense block where the output of each conv_block is fed to subsequent ones'''\n",
    "    concat_feat = x\n",
    "    for i in range(nb_layers):\n",
    "        branch = i+1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate)\n",
    "        concat_feat = Concatenate(axis=concat_axis)([concat_feat, x])\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter\n",
    "\n",
    "\n",
    "# Data Loading for Medicinal Leaf Dataset\n",
    "def load_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "    random.seed(42)\n",
    "    \n",
    "    dataset_path = \"Medicinal Leaf Dataset/Segmented Medicinal Leaf Images/\"\n",
    "    class_folders = sorted(list(os.listdir(dataset_path)))\n",
    "    \n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        for img_name in sorted(os.listdir(class_path)):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            image = img_to_array(image)\n",
    "            data.append(image)\n",
    "            labels.append(class_name)\n",
    "    \n",
    "    data = np.array(data, dtype=\"float32\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Convert labels to binary format\n",
    "    mlb = LabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    (xtrain, xtest, ytrain, ytest) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "    \n",
    "    return xtrain, ytrain, xtest, ytest\n",
    "\n",
    "\n",
    "# Main Script\n",
    "if __name__ == '__main__':\n",
    "    img_rows, img_cols = 224, 224  # Image dimensions\n",
    "    channel = 3                    # Number of color channels\n",
    "    num_classes = 30               # Number of classes (30 leaf categories)\n",
    "    batch_size = 16\n",
    "    nb_epoch = 10\n",
    "\n",
    "    # Load the dataset\n",
    "    X_train, Y_train, X_valid, Y_valid = load_data()\n",
    "\n",
    "    # Initialize and compile DenseNet201 model\n",
    "    model = densenet201_model(img_rows=img_rows, img_cols=img_cols, color_type=channel, num_classes=num_classes)\n",
    "    \n",
    "    # Model checkpoint to save the best model\n",
    "    filepath = \"bestmodel_densenet201.keras\"  # Change .hdf5 to .keras\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, shuffle=True, verbose=1,\n",
    "                        validation_data=(X_valid, Y_valid), callbacks=callbacks_list)\n",
    "\n",
    "    # Plotting training results\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    xtest = X_valid\n",
    "    ytest = Y_valid\n",
    "    ypred = model.predict(xtest)\n",
    "    total = 0\n",
    "    accurate = 0\n",
    "    for i in range(len(ypred)):\n",
    "        if np.argmax(ypred[i]) == np.argmax(ytest[i]):\n",
    "            accurate += 1\n",
    "        total += 1\n",
    "\n",
    "    print('Accuracy: ', (accurate / total) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38710780-8e2b-4bc6-8a71-85eeabc62d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
